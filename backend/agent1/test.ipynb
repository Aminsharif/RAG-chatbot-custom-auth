{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f10fa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedStatusCodeError",
     "evalue": "Meta endpoint! Unexpected status code: 404, with response body: None.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m weaviate_api_key = os.environ[\u001b[33m\"\u001b[39m\u001b[33mWEAVIATE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Connect to Weaviate Cloud\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m client = \u001b[43mweaviate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_to_weaviate_cloud\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcluster_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAuth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweaviate_api_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(client.is_ready())\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\helpers.py:107\u001b[39m, in \u001b[36mconnect_to_weaviate_cloud\u001b[39m\u001b[34m(cluster_url, auth_credentials, headers, additional_config, skip_init_checks)\u001b[39m\n\u001b[32m    104\u001b[39m     _Warnings.oidc_with_wcd_deprecated()\n\u001b[32m    106\u001b[39m cluster_url, grpc_host = __parse_weaviate_cloud_cluster_url(cluster_url)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mWeaviateClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconnection_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConnectionParams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mProtocolParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcluster_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m443\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgrpc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mProtocolParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrpc_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m443\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_client_secret\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__parse_auth_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_credentials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43madditional_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_init_checks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_init_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\helpers.py:371\u001b[39m, in \u001b[36m__connect\u001b[39m\u001b[34m(client)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    370\u001b[39m     client.close()\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\helpers.py:367\u001b[39m, in \u001b[36m__connect\u001b[39m\u001b[34m(client)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__connect\u001b[39m(client: WeaviateClient) -> WeaviateClient:\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m         \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m client\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\client_executor.py:149\u001b[39m, in \u001b[36m_WeaviateClientExecutor.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> executor.Result[\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Connect to the Weaviate instance performing all the necessary checks.\u001b[39;00m\n\u001b[32m    139\u001b[39m \n\u001b[32m    140\u001b[39m \u001b[33;03m    If you have specified `skip_init_checks` in the constructor then this method will not perform any runtime checks\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        weaviate.exceptions.UnexpectedStatusCodeError: If weaviate reports a none OK status.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:99\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, \u001b[43mexception_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:38\u001b[39m, in \u001b[36mraise_exception\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_exception\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:80\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\n\u001b[32m     72\u001b[39m     method: SyncOrAsyncMethod[P, R],\n\u001b[32m     73\u001b[39m     response_callback: SyncOrAsyncCallback[R, T, A],\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m ) -> Union[T, Awaitable[T], Awaitable[A]]:\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# wrap method call in try-except to catch exceptions for sync method\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         call = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(call, Awaitable):\n\u001b[32m     83\u001b[39m             \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute\u001b[39m() -> T:\n\u001b[32m     84\u001b[39m                 \u001b[38;5;66;03m# wrap await in try-except to catch exceptions for async method\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:890\u001b[39m, in \u001b[36mConnectionSync.connect\u001b[39m\u001b[34m(self, force)\u001b[39m\n\u001b[32m    888\u001b[39m \u001b[38;5;66;03m# need this to get the version of weaviate for version checks and proper GRPC configuration\u001b[39;00m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m     meta = executor.result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    891\u001b[39m     \u001b[38;5;28mself\u001b[39m._weaviate_version = _ServerVersion.from_string(meta[\u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    892\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgrpcMaxMessageSize\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:857\u001b[39m, in \u001b[36m_ConnectionBase.get_meta\u001b[39m\u001b[34m(self, check_is_connected)\u001b[39m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/meta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_is_connected\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_is_connected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:99\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, \u001b[43mexception_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:38\u001b[39m, in \u001b[36mraise_exception\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_exception\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\executor.py:95\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, exception_callback(e))\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _execute()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m resp_call = \u001b[43mresponse_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp_call, Awaitable)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\connect\\v4.py:853\u001b[39m, in \u001b[36m_ConnectionBase.get_meta.<locals>.resp\u001b[39m\u001b[34m(res)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresp\u001b[39m(res: Response) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m     data = \u001b[43m_decode_json_response_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMeta endpoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\weaviate\\util.py:696\u001b[39m, in \u001b[36m_decode_json_response_dict\u001b[39m\u001b[34m(response, location)\u001b[39m\n\u001b[32m    693\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (httpx.DecodingError, json.decoder.JSONDecodeError):\n\u001b[32m    694\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseCannotBeDecodedError(location, response)\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedStatusCodeError(location, response)\n",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m: Meta endpoint! Unexpected status code: 404, with response body: None."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Best practice: store your credentials in environment variables\n",
    "weaviate_url = os.environ[\"WEAVIATE_URL\"]\n",
    "weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72df6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_url = os.environ.get(\"WEAVIATE_URL\")\n",
    "weaviate_api_key = os.environ.get(\"WEAVIATE_API_KEY\")\n",
    "import weaviate\n",
    "from weaviate import Client\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.query import Filter\n",
    "\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccee906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_project\\RAG-chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "\n",
    "def get_embeddings_model() -> Embeddings:\n",
    "    return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = WeaviateVectorStore(\n",
    "            client=client,\n",
    "            index_name=\"pdf_index\",\n",
    "            text_key=\"text\",\n",
    "            embedding=get_embeddings_model(),\n",
    "            attributes=[\"source\", \"title\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975655fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc5df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ret.invoke(\"what is transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242aba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'keywords': '', 'creator': 'LaTeX with hyperref', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '3', 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'file_name': 'Attention.pdf', 'page': 2.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(metadata={'keywords': '', 'creator': 'LaTeX with hyperref', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '5', 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'file_name': 'Attention.pdf', 'page': 4.0, 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'subject': '', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='The Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward'),\n",
       " Document(metadata={'creator': 'LaTeX with hyperref', 'keywords': '', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\LLM.pdf', 'trapped': '/False', 'page_label': '5', 'creationdate': datetime.datetime(2024, 4, 11, 0, 8, 1, tzinfo=datetime.timezone.utc), 'file_name': 'LLM.pdf', 'page': 4.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'subject': '', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/LLM.pdf', 'total_pages': 46.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 11, 0, 8, 1, tzinfo=datetime.timezone.utc), 'title': 'A Comprehensive Overview of Large Language Models', 'author': 'Humza Naveed; Asad Ullah Khan; Shi Qiu; Muhammad Saqib; Saeed Anwar; Muhammad Usman; Naveed Akhtar; Nick Barnes; Ajmal Mian;'}, page_content='collected through web sources. This data contains private\\ninformation; therefore, many LLMs employ heuristics-based\\nmethods to filter information such as names, addresses, and\\nphone numbers to avoid learning personal information.\\n2.9. Architectures\\nHere we discuss the variants of the transformer architectures\\nused in LLMs. The di fference arises due to the application of\\nFigure 4: An example of attention patterns in language models, image is taken\\nfrom [93].\\nFigure 5: An example of language model training objectives, image from [93].\\nthe attention and the connection of transformer blocks. An il-\\nlustration of attention patterns of these architectures is shown\\nin Figure 4.\\nEncoder Decoder: This architecture processes inputs through\\nthe encoder and passes the intermediate representation to the\\ndecoder to generate the output. Here, the encoder sees the\\ncomplete sequence utilizing self-attention whereas the decoder\\nprocesses the sequence one after the other with implementing'),\n",
       " Document(metadata={'creator': 'LaTeX with hyperref', 'keywords': '', 'file_path': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf\\\\Attention.pdf', 'trapped': '/False', 'page_label': '10', 'creationdate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'file_name': 'Attention.pdf', 'page': 9.0, 'ptex_fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'directory': 'C:\\\\Users\\\\amins\\\\AppData\\\\Local\\\\Temp\\\\ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf', 'source': 'C:/Users/amins/AppData/Local/Temp/ingest_74749f49-8a8b-4c2a-bb40-c934519a72f8_1y378oaf/Attention.pdf', 'total_pages': 15.0, 'producer': 'pdfTeX-1.40.25', 'moddate': datetime.datetime(2024, 4, 10, 21, 11, 43, tzinfo=datetime.timezone.utc), 'title': '', 'author': ''}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f0e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_project\\RAG-chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "from typing import cast, Optional, Any\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import field\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from backend import retrieval\n",
    "from backend.configuration import Configuration, IndexConfiguration\n",
    "from backend.state import InputState, State\n",
    "from backend.utils import format_docs, get_message_text, load_chat_model\n",
    "\n",
    "# Your ProdDBConfig class with user-specific configurations\n",
    "class ProdDBConfig:\n",
    "    @staticmethod\n",
    "    def _build_uri() -> str:\n",
    "        \"\"\"Production URI with pooling, SSL, timeouts.\"\"\"\n",
    "        return (\n",
    "            \"postgresql://postgres:123456@localhost:5432/langgraphrag?\"\n",
    "            \"sslmode=disable&\"\n",
    "            \"connect_timeout=10\"\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def checkpointer() -> PostgresSaver:\n",
    "        \"\"\"Get checkpointer instance.\"\"\"\n",
    "        uri = ProdDBConfig._build_uri()\n",
    "        return PostgresSaver.from_conn_string(uri)\n",
    "    \n",
    "    @staticmethod\n",
    "    def store() -> PostgresStore:\n",
    "        \"\"\"Get store instance.\"\"\"\n",
    "        uri = ProdDBConfig._build_uri()\n",
    "        return PostgresStore.from_conn_string(uri)\n",
    "\n",
    "    @staticmethod\n",
    "    @contextmanager\n",
    "    def get_store_context():\n",
    "        \"\"\"Context manager for store operations.\"\"\"\n",
    "        store = ProdDBConfig.store()\n",
    "        try:\n",
    "            yield store\n",
    "        finally:\n",
    "            if hasattr(store, 'close'):\n",
    "                store.close()\n",
    "\n",
    "# Health check helper\n",
    "def db_health_check():\n",
    "    \"\"\"Verify DB connectivity.\"\"\"\n",
    "    try:\n",
    "        with ProdDBConfig.get_store_context() as store:\n",
    "            print(\"Store connection successful\")\n",
    "        print(\"Database health check passed\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Database health check failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Define the function that calls the model\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"Search the indexed documents for a query.\"\"\"\n",
    "    query: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StateGraph.compile() got an unexpected keyword argument 'config_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 151\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Finally, we compile it with checkpointing!\u001b[39;00m\n\u001b[32m    149\u001b[39m checkpointer = ProdDBConfig.checkpointer()\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m graph = \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m graph.name = \u001b[33m\"\u001b[39m\u001b[33mRetrievalGraph\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: StateGraph.compile() got an unexpected keyword argument 'config_schema'"
     ]
    }
   ],
   "source": [
    "\n",
    "async def generate_query(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, list[str]]:\n",
    "    \"\"\"Generate a search query based on the current state and configuration.\"\"\"\n",
    "    messages = state.messages\n",
    "    \n",
    "    # Get configuration with user_id\n",
    "    configuration = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    if len(messages) == 1:\n",
    "        human_input = get_message_text(messages[-1])\n",
    "        return {\"queries\": [human_input]}\n",
    "    else:\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", configuration.query_system_prompt),\n",
    "                (\"placeholder\", \"{messages}\"),\n",
    "            ]\n",
    "        )\n",
    "        model = load_chat_model(configuration.query_model).with_structured_output(\n",
    "            SearchQuery\n",
    "        )\n",
    "\n",
    "        message_value = await prompt.ainvoke(\n",
    "            {\n",
    "                \"messages\": state.messages,\n",
    "                \"queries\": \"\\n- \".join(state.queries),\n",
    "                \"system_time\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "                \"user_id\": configuration.user_id,  # Include user_id in context\n",
    "            },\n",
    "            config,\n",
    "        )\n",
    "        generated = cast(SearchQuery, await model.ainvoke(message_value, config))\n",
    "        return {\n",
    "            \"queries\": [generated.query],\n",
    "        }\n",
    "\n",
    "async def retrieve(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, list[Document]]:\n",
    "    \"\"\"Retrieve documents based on the latest query in the state.\"\"\"\n",
    "    # Get configuration including IndexConfiguration\n",
    "    configuration = Configuration.from_runnable_config(config)\n",
    "    user_id = configuration.user_id\n",
    "    \n",
    "    # Store user query in database for history\n",
    "    with ProdDBConfig.get_store_context() as store:\n",
    "        query_data = {\n",
    "            \"query\": state.queries[-1],\n",
    "            \"user_id\": user_id,\n",
    "            \"timestamp\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "            \"metadata\": {\n",
    "                \"retriever_provider\": configuration.retriever_provider,\n",
    "                \"embedding_model\": configuration.embedding_model\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Store query with user-specific key\n",
    "        query_id = f\"query_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}\"\n",
    "        store.put(query_id, query_data)\n",
    "    \n",
    "    # Use the retriever with user-specific filtering\n",
    "    with retrieval.make_retriever(config) as retriever:\n",
    "        # If your retriever supports filtering by metadata, apply user filter\n",
    "        if hasattr(config, 'metadata_filter'):\n",
    "            config.metadata_filter = {\"user_id\": user_id}\n",
    "        \n",
    "        # Also pass user_id in search kwargs if supported\n",
    "        search_kwargs = configuration.search_kwargs.copy()\n",
    "        search_kwargs[\"metadata_filter\"] = {\"user_id\": user_id}\n",
    "        \n",
    "        response = await retriever.ainvoke(\n",
    "            state.queries[-1], \n",
    "            config={**config, \"search_kwargs\": search_kwargs}\n",
    "        )\n",
    "        return {\"retrieved_docs\": response}\n",
    "\n",
    "async def respond(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, list[BaseMessage]]:\n",
    "    \"\"\"Call the LLM powering our \"agent\".\"\"\"\n",
    "    configuration = Configuration.from_runnable_config(config)\n",
    "    user_id = configuration.user_id\n",
    "    \n",
    "    # Store conversation in the database with user filtering\n",
    "    with ProdDBConfig.get_store_context() as store:\n",
    "        # Store conversation metadata with user_id\n",
    "        conversation_data = {\n",
    "            \"user_id\": user_id,\n",
    "            \"messages\": [msg.dict() for msg in state.messages],\n",
    "            \"queries\": state.queries,\n",
    "            \"retrieved_docs\": [doc.dict() for doc in state.retrieved_docs],\n",
    "            \"timestamp\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "            \"configuration\": {\n",
    "                \"retriever_provider\": configuration.retriever_provider,\n",
    "                \"embedding_model\": configuration.embedding_model\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Store with user-specific key\n",
    "        conversation_id = f\"conversation_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        store.put(conversation_id, conversation_data)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", configuration.response_system_prompt),\n",
    "            (\"placeholder\", \"{messages}\"),\n",
    "        ]\n",
    "    )\n",
    "    model = load_chat_model(configuration.response_model)\n",
    "\n",
    "    retrieved_docs = format_docs(state.retrieved_docs)\n",
    "    message_value = await prompt.ainvoke(\n",
    "        {\n",
    "            \"messages\": state.messages,\n",
    "            \"retrieved_docs\": retrieved_docs,\n",
    "            \"system_time\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "            \"user_id\": user_id,  # Include user_id in prompt context\n",
    "        },\n",
    "        config,\n",
    "    )\n",
    "    response = await model.ainvoke(message_value, config)\n",
    "    \n",
    "    # Store the response separately\n",
    "    with ProdDBConfig.get_store_context() as store:\n",
    "        response_data = {\n",
    "            \"user_id\": user_id,\n",
    "            \"query\": state.queries[-1] if state.queries else \"\",\n",
    "            \"response\": response.content if hasattr(response, 'content') else str(response),\n",
    "            \"timestamp\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "            \"conversation_id\": conversation_id\n",
    "        }\n",
    "        response_key = f\"response_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}\"\n",
    "        store.put(response_key, response_data)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define a new graph\n",
    "builder = StateGraph(State, input_schema=InputState, context_schema=Configuration)\n",
    "\n",
    "builder.add_node(generate_query)\n",
    "builder.add_node(retrieve)\n",
    "builder.add_node(respond)\n",
    "builder.add_edge(\"__start__\", \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"respond\")\n",
    "\n",
    "# Finally, we compile it with checkpointing!\n",
    "checkpointer = ProdDBConfig.checkpointer()\n",
    "\n",
    "graph = builder.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    interrupt_before=[],\n",
    "    interrupt_after=[],\n",
    ")\n",
    "graph.name = \"RetrievalGraph\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enhanced functions for user-specific operations\n",
    "def load_user_conversation(thread_id: str, user_id: str, config: Optional[dict] = None):\n",
    "    \"\"\"Load a conversation from checkpoint by thread ID for specific user.\"\"\"\n",
    "    configurable = {\n",
    "        \"thread_id\": thread_id,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "    if config:\n",
    "        configurable.update(config.get(\"configurable\", {}))\n",
    "    \n",
    "    return graph.get_state({\"configurable\": configurable})\n",
    "\n",
    "def list_user_conversations(user_id: str, limit: int = 100):\n",
    "    \"\"\"List all stored conversation thread IDs for a specific user.\"\"\"\n",
    "    with ProdDBConfig.checkpointer() as cp:\n",
    "        # This will need adjustment based on your PostgresSaver implementation\n",
    "        # You might need to implement custom filtering\n",
    "        all_conversations = cp.list({\"configurable\": {}}, limit=limit)\n",
    "        \n",
    "        # Filter by user_id if stored in checkpoint metadata\n",
    "        user_conversations = []\n",
    "        for conv in all_conversations:\n",
    "            if hasattr(conv, 'metadata') and conv.metadata.get('user_id') == user_id:\n",
    "                user_conversations.append(conv)\n",
    "        \n",
    "        return user_conversations\n",
    "\n",
    "def get_user_conversation_history(user_id: str, limit: int = 50):\n",
    "    \"\"\"Get conversation history from store for a specific user.\"\"\"\n",
    "    with ProdDBConfig.get_store_context() as store:\n",
    "        # This assumes your store supports scanning or querying by prefix\n",
    "        # Adjust based on your PostgresStore implementation\n",
    "        conversations = []\n",
    "        \n",
    "        # Try to get conversations by pattern\n",
    "        # Note: Actual implementation depends on your store's query capabilities\n",
    "        try:\n",
    "            # If store has scan or query capabilities\n",
    "            if hasattr(store, 'scan'):\n",
    "                for key, value in store.scan():\n",
    "                    if key.startswith(f\"conversation_{user_id}_\"):\n",
    "                        conversations.append({\n",
    "                            \"id\": key,\n",
    "                            \"data\": value,\n",
    "                            \"timestamp\": value.get(\"timestamp\", \"\")\n",
    "                        })\n",
    "            \n",
    "            # Sort by timestamp\n",
    "            conversations.sort(key=lambda x: x.get(\"timestamp\", \"\"), reverse=True)\n",
    "            \n",
    "            return conversations[:limit]\n",
    "        except:\n",
    "            # Fallback - store implementation might differ\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03959670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Health check\n",
    "    if db_health_check():\n",
    "        print(\"Database is ready\")\n",
    "        \n",
    "        # Example: Invoke the graph with user-specific configuration\n",
    "        user_id = \"user_12345\"  # Or use UUID\n",
    "        config = {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": f\"{user_id}_session_1\",\n",
    "                \"user_id\": user_id,\n",
    "                \"retriever_provider\": \"weaviate\",\n",
    "                \"embedding_model\": \"all-MiniLM-L6-v2\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # This will automatically filter and store data for this user\n",
    "        result = graph.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]},\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        print(\"Response:\", result[\"messages\"][-1].content)\n",
    "        \n",
    "        # Get user's conversation history\n",
    "        history = get_user_conversation_history(user_id, limit=10)\n",
    "        print(f\"\\nUser {user_id} has {len(history)} conversations\")\n",
    "        \n",
    "        # Continue conversation with same user\n",
    "        result2 = graph.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me more about that\"}]},\n",
    "            config=config  # Same thread_id and user_id will load previous state\n",
    "        )\n",
    "        \n",
    "        print(\"\\nFollow-up response:\", result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5512e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main entrypoint for the conversational retrieval graph with user memory.\n",
    "\n",
    "This module defines the core structure and functionality of the conversational\n",
    "retrieval graph with stateful user preferences via langgraph.json store.\n",
    "Supports cross-thread memory (user prefs) + thread-scoped history.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Annotated, TypedDict, cast, Sequence\n",
    "from operator import add\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel as PydanticBaseModel\n",
    "\n",
    "from backend import retrieval\n",
    "from backend.configuration import Configuration\n",
    "from backend.state import InputState, State  # Assume State updated below\n",
    "from backend.utils import format_docs, get_message_text, load_chat_model\n",
    "\n",
    "# User preference schema for tools\n",
    "class UserInfo(PydanticBaseModel):\n",
    "    \"\"\"User preferences schema.\"\"\"\n",
    "    name: str = Field(..., description=\"User's full name\")\n",
    "    favorite_topics: list[str] = Field(default_factory=list, description=\"Favorite topics\")\n",
    "    preferred_format: str = Field(default=\"detailed\", description=\"Response style: brief/detailed\")\n",
    "\n",
    "# Memory tools - access store via config[\"store\"] (langgraph.json injection)\n",
    "@tool\n",
    "async def get_user_prefs(runtime: Any) -> str:\n",
    "    \"\"\"Get stored preferences for current user.\"\"\"\n",
    "    store = runtime.config.get(\"store\")\n",
    "    if not store:\n",
    "        return \"No store available.\"\n",
    "    user_id = runtime.config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"users\", user_id)\n",
    "    item = await store.aget(namespace, \"profile\")\n",
    "    if item and item.value:\n",
    "        prefs = item.value\n",
    "        return f\"Name: {prefs.get('name', 'Unknown')}\\nTopics: {prefs.get('favorite_topics', [])}\\nFormat: {prefs.get('preferred_format', 'detailed')}\"\n",
    "    return \"No preferences stored yet.\"\n",
    "\n",
    "@tool\n",
    "async def save_user_prefs(info: UserInfo, runtime: Any) -> str:\n",
    "    \"\"\"Save/update user preferences.\"\"\"\n",
    "    store = runtime.config.get(\"store\")\n",
    "    if not store:\n",
    "        return \"No store available.\"\n",
    "    user_id = runtime.config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"users\", user_id)\n",
    "    await store.aput(namespace, \"profile\", info.model_dump())\n",
    "    return \"Preferences saved!\"\n",
    "\n",
    "class SearchQuery(PydanticBaseModel):\n",
    "    \"\"\"Search the indexed documents for a query.\"\"\"\n",
    "    query: str\n",
    "\n",
    "async def generate_query(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, list[str]]:\n",
    "    \"\"\"Generate a search query based on the current state and configuration.\"\"\"\n",
    "    messages = state.messages\n",
    "    if len(messages) == 1:\n",
    "        human_input = get_message_text(messages[-1])\n",
    "        return {\"queries\": [human_input]}\n",
    "    else:\n",
    "        configuration = Configuration.from_runnable_config(config)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", configuration.query_system_prompt),\n",
    "            (\"placeholder\", \"{messages}\"),\n",
    "        ])\n",
    "        model = load_chat_model(configuration.query_model).with_structured_output(SearchQuery)\n",
    "\n",
    "        message_value = await prompt.ainvoke({\n",
    "            \"messages\": state.messages,\n",
    "            \"queries\": \"\\n- \".join(state.queries),\n",
    "            \"system_time\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "        }, config)\n",
    "        generated = cast(SearchQuery, await model.ainvoke(message_value, config))\n",
    "        return {\"queries\": [generated.query]}\n",
    "\n",
    "async def retrieve(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, list[Document]]:\n",
    "    \"\"\"Retrieve documents based on the latest query in the state.\"\"\"\n",
    "    with retrieval.make_retriever(config) as retriever:\n",
    "        response = await retriever.ainvoke(state.queries[-1], config)\n",
    "        return {\"retrieved_docs\": response}\n",
    "\n",
    "async def respond(\n",
    "    state: State, *, config: RunnableConfig\n",
    ") -> dict[str, Sequence[BaseMessage]]:\n",
    "    \"\"\"Enhanced respond with user memory injection + tools.\"\"\"\n",
    "    store = config.get(\"store\")  # langgraph.json injects AsyncPostgresStore\n",
    "    configuration = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Load user prefs from store\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"users\", user_id)\n",
    "    profile_item = await store.aget(namespace, \"profile\") if store else None\n",
    "    \n",
    "    user_context = \"\"\n",
    "    if profile_item and profile_item.value:\n",
    "        prefs = profile_item.value\n",
    "        user_context = (\n",
    "            f\"User preferences: Name={prefs.get('name', 'Unknown')}, \"\n",
    "            f\"Topics={prefs.get('favorite_topics', [])}, \"\n",
    "            f\"Format={prefs.get('preferred_format', 'detailed')}.\\n\"\n",
    "            f\"Adapt responses accordingly.\"\n",
    "        )\n",
    "    \n",
    "    # Enhanced prompt with user context\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"{configuration.response_system_prompt}\\n\\n{user_context}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ])\n",
    "    \n",
    "    model = load_chat_model(configuration.response_model)\n",
    "    # Bind memory tools\n",
    "    model_with_tools = model.bind_tools([get_user_prefs, save_user_prefs])\n",
    "    \n",
    "    retrieved_docs = format_docs(state.retrieved_docs)\n",
    "    message_value = await prompt.ainvoke({\n",
    "        \"messages\": state.messages,\n",
    "        \"retrieved_docs\": retrieved_docs,\n",
    "        \"system_time\": datetime.now(tz=timezone.utc).isoformat(),\n",
    "    }, config)\n",
    "    \n",
    "    # Invoke with store access for tools\n",
    "    response = await model_with_tools.ainvoke(message_value, config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Updated State (add annotations if needed)\n",
    "class RetrievalState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    queries: Annotated[list[str], add]\n",
    "    retrieved_docs: list[Document]\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(RetrievalState, input_schema=InputState)  # Use your InputState\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"retrieve\", retrieve)\n",
    "builder.add_node(\"respond\", respond)\n",
    "\n",
    "builder.add_edge(\"__start__\", \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"respond\")\n",
    "builder.add_edge(\"respond\", END)\n",
    "\n",
    "# NO manual store/checkpointer - langgraph.json handles it!\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[],\n",
    "    interrupt_after=[],\n",
    ")\n",
    "graph.name = \"RetrievalGraph\"\n",
    "\n",
    "# Example usage function\n",
    "async def chat_example():\n",
    "    config = {\"configurable\": {\"thread_id\": \"chat1\", \"user_id\": \"alice123\"}}\n",
    "    \n",
    "    # Session 1: Learns prefs + retrieves\n",
    "    result1 = await graph.ainvoke({\n",
    "        \"messages\": [HumanMessage(content=\"Hi I'm Alice, love hiking/tech. What's RAG?\")]\n",
    "    }, config)\n",
    "    print(\"Response 1:\", result1[\"messages\"][-1].content)\n",
    "    \n",
    "    # New thread: Uses prefs in retrieval context!\n",
    "    config2 = {\"configurable\": {\"thread_id\": \"chat2\", \"user_id\": \"alice123\"}}\n",
    "    result2 = await graph.ainvoke({\n",
    "        \"messages\": [HumanMessage(content=\"More on RAG, make it brief\")]\n",
    "    }, config2)\n",
    "    print(\"Response 2:\", result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afc744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "from pydantic import BaseModel, HttpUrl\n",
    "from typing import Optional, List\n",
    "from enum import Enum\n",
    "\n",
    "class IndexingStrategy(str, Enum):\n",
    "    SITEMAP = \"sitemap\"\n",
    "    RECURSIVE = \"recursive\"\n",
    "    CUSTOM = \"custom\"\n",
    "\n",
    "class WebsiteConfig(BaseModel):\n",
    "    url: HttpUrl\n",
    "    name: str\n",
    "    index_name: str\n",
    "    strategy: IndexingStrategy = IndexingStrategy.SITEMAP\n",
    "    filter_urls: Optional[List[str]] = None\n",
    "    allowed_domains: Optional[List[str]] = None\n",
    "    max_depth: Optional[int] = 2\n",
    "    chunk_size: int = 4000\n",
    "    chunk_overlap: int = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7e2847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (2.12.5)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.3-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (2.4.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (4.0.1)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2026.1.4)\n",
      "Requirement already satisfied: packaging>=24.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=4.19.0->chromadb)\n",
      "  Downloading rpds_py-0.30.0-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: protobuf in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
      "Requirement already satisfied: sympy in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.12.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\chatbot_project\\rag-chatbot-custom-auth\\venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl (21.4 MB)\n",
      "   ---------------------------------------- 0.0/21.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/21.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/21.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/21.4 MB 1.2 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.8/21.4 MB 990.6 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/21.4 MB 990.6 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 1.0/21.4 MB 943.9 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 1.3/21.4 MB 950.9 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 1.6/21.4 MB 977.4 kB/s eta 0:00:21\n",
      "   --- ------------------------------------ 1.8/21.4 MB 986.0 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 2.1/21.4 MB 1.0 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 2.4/21.4 MB 1.0 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 2.6/21.4 MB 1.1 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 2.9/21.4 MB 1.1 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 3.1/21.4 MB 1.1 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 3.4/21.4 MB 1.1 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 3.7/21.4 MB 1.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 3.9/21.4 MB 1.1 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 4.2/21.4 MB 1.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 4.5/21.4 MB 1.1 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 4.7/21.4 MB 1.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 5.0/21.4 MB 1.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 5.2/21.4 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 5.5/21.4 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 5.8/21.4 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 5.8/21.4 MB 1.2 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 6.0/21.4 MB 1.1 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 6.3/21.4 MB 1.1 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 6.6/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 6.8/21.4 MB 1.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.1/21.4 MB 845.6 kB/s eta 0:00:17\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 7.3/21.4 MB 664.9 kB/s eta 0:00:22\n",
      "   -------------- ------------------------- 7.6/21.4 MB 572.2 kB/s eta 0:00:25\n",
      "   -------------- ------------------------- 7.6/21.4 MB 572.2 kB/s eta 0:00:25\n",
      "   -------------- ------------------------- 7.9/21.4 MB 570.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 7.9/21.4 MB 570.5 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 7.9/21.4 MB 570.5 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 8.1/21.4 MB 569.0 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 8.1/21.4 MB 569.0 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 8.4/21.4 MB 569.6 kB/s eta 0:00:23\n",
      "   --------------- ------------------------ 8.4/21.4 MB 569.6 kB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 8.7/21.4 MB 571.5 kB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 8.7/21.4 MB 571.5 kB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 8.9/21.4 MB 574.0 kB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 8.9/21.4 MB 574.0 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 9.2/21.4 MB 576.5 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 9.4/21.4 MB 579.1 kB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 9.4/21.4 MB 579.1 kB/s eta 0:00:21\n",
      "   ------------------ --------------------- 9.7/21.4 MB 583.8 kB/s eta 0:00:21\n",
      "   ------------------ --------------------- 9.7/21.4 MB 583.8 kB/s eta 0:00:21\n",
      "   ------------------ --------------------- 10.0/21.4 MB 588.5 kB/s eta 0:00:20\n",
      "   ------------------- -------------------- 10.2/21.4 MB 592.6 kB/s eta 0:00:19\n",
      "   ------------------- -------------------- 10.5/21.4 MB 598.7 kB/s eta 0:00:19\n",
      "   ------------------- -------------------- 10.5/21.4 MB 598.7 kB/s eta 0:00:19\n",
      "   -------------------- ------------------- 10.7/21.4 MB 604.6 kB/s eta 0:00:18\n",
      "   -------------------- ------------------- 11.0/21.4 MB 612.2 kB/s eta 0:00:17\n",
      "   --------------------- ------------------ 11.3/21.4 MB 619.7 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 11.8/21.4 MB 635.5 kB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 12.1/21.4 MB 644.5 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.3/21.4 MB 653.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 12.6/21.4 MB 597.9 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 12.8/21.4 MB 574.7 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 12.8/21.4 MB 574.7 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 12.8/21.4 MB 574.7 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 12.8/21.4 MB 574.7 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 12.8/21.4 MB 574.7 kB/s eta 0:00:15\n",
      "   ------------------------ --------------- 13.1/21.4 MB 561.7 kB/s eta 0:00:15\n",
      "   ------------------------- -------------- 13.4/21.4 MB 567.5 kB/s eta 0:00:15\n",
      "   ------------------------- -------------- 13.6/21.4 MB 574.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 13.9/21.4 MB 580.4 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 14.2/21.4 MB 586.5 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 14.4/21.4 MB 592.8 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 14.7/21.4 MB 598.9 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 14.9/21.4 MB 604.9 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 15.2/21.4 MB 610.7 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 15.5/21.4 MB 615.9 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 15.7/21.4 MB 621.4 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 16.0/21.4 MB 625.8 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 16.3/21.4 MB 630.8 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 16.5/21.4 MB 634.9 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 16.5/21.4 MB 634.9 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 16.8/21.4 MB 637.6 kB/s eta 0:00:08\n",
      "   -------------------------------- ------- 17.3/21.4 MB 649.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 17.3/21.4 MB 649.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 17.6/21.4 MB 653.8 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 17.8/21.4 MB 658.3 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 18.1/21.4 MB 662.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 18.4/21.4 MB 667.1 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 18.6/21.4 MB 671.4 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 18.9/21.4 MB 675.7 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 18.9/21.4 MB 675.7 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 19.4/21.4 MB 682.1 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 19.7/21.4 MB 687.7 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 19.9/21.4 MB 691.8 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 20.2/21.4 MB 695.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 20.4/21.4 MB 699.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 20.7/21.4 MB 703.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  21.0/21.4 MB 707.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  21.2/21.4 MB 710.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 21.4/21.4 MB 711.9 kB/s  0:00:29\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading build-1.4.0-py3-none-any.whl (24 kB)\n",
      "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.4 MB/s  0:00:01\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading mmh3-5.2.0-cp313-cp313-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.23.2-cp313-cp313-win_amd64.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.5 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/13.5 MB 1.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/13.5 MB 1.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.3/13.5 MB 1.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.6/13.5 MB 1.5 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.8/13.5 MB 1.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 2.1/13.5 MB 1.4 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.4/13.5 MB 1.4 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.6/13.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.9/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 3.1/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.4/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.7/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.9/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.2/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.5/13.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/13.5 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 5.0/13.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 5.2/13.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.5/13.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.8/13.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.0/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 6.3/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.6/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.8/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.8/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.1/13.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.3/13.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 7.6/13.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.9/13.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.1/13.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.4/13.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 8.7/13.5 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 8.9/13.5 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.2/13.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 9.4/13.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 9.7/13.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.0/13.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.2/13.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.5/13.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.7/13.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.0/13.5 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.3/13.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.5/13.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 11.8/13.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.1/13.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.3/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.6/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 1.2 MB/s  0:00:10\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pybase64-1.4.3-cp313-cp313-win_amd64.whl (35 kB)\n",
      "Downloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rich-14.3.1-py3-none-any.whl (309 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.30.0-cp313-cp313-win_amd64.whl (240 kB)\n",
      "Downloading typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl (85 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, websocket-client, shellingham, rpds-py, pyreadline3, pyproject_hooks, pybase64, overrides, oauthlib, mmh3, mdurl, importlib-resources, httptools, backoff, requests-oauthlib, referencing, posthog, markdown-it-py, humanfriendly, build, rich, kubernetes, jsonschema-specifications, coloredlogs, typer, onnxruntime, jsonschema, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\n",
      "   --- ------------------------------------  3/31 [websocket-client]\n",
      "   ------- --------------------------------  6/31 [pyreadline3]\n",
      "   ----------- ----------------------------  9/31 [overrides]\n",
      "   ------------ --------------------------- 10/31 [oauthlib]\n",
      "   ------------------- -------------------- 15/31 [backoff]\n",
      "   --------------------- ------------------ 17/31 [referencing]\n",
      "   ----------------------- ---------------- 18/31 [posthog]\n",
      "   ------------------------ --------------- 19/31 [markdown-it-py]\n",
      "   ------------------------ --------------- 19/31 [markdown-it-py]\n",
      "   ------------------------- -------------- 20/31 [humanfriendly]\n",
      "   ---------------------------- ----------- 22/31 [rich]\n",
      "   ---------------------------- ----------- 22/31 [rich]\n",
      "   ---------------------------- ----------- 22/31 [rich]\n",
      "   ---------------------------- ----------- 22/31 [rich]\n",
      "   ---------------------------- ----------- 22/31 [rich]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ----------------------------- ---------- 23/31 [kubernetes]\n",
      "   ------------------------------ --------- 24/31 [jsonschema-specifications]\n",
      "   --------------------------------- ------ 26/31 [typer]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ---------------------------------- ----- 27/31 [onnxruntime]\n",
      "   ------------------------------------ --- 28/31 [jsonschema]\n",
      "   ------------------------------------ --- 28/31 [jsonschema]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   -------------------------------------- - 30/31 [chromadb]\n",
      "   ---------------------------------------- 31/31 [chromadb]\n",
      "\n",
      "Successfully installed backoff-2.2.1 build-1.4.0 chromadb-1.4.1 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.12.19 httptools-0.7.1 humanfriendly-10.0 importlib-resources-6.5.2 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 kubernetes-35.0.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-exporter-otlp-proto-grpc-1.39.1 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.3 pypika-0.50.0 pyproject_hooks-1.2.0 pyreadline3-3.5.4 referencing-0.37.0 requests-oauthlib-2.0.0 rich-14.3.1 rpds-py-0.30.0 shellingham-1.5.4 typer-0.21.1 websocket-client-1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "d:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\IPython\\utils\\_process_win32.py:138: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  res = process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34222049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Generator\n",
    "\n",
    "from bs4 import BeautifulSoup, Doctype, NavigableString, Tag\n",
    "def langchain_docs_extractor(soup: BeautifulSoup) -> str:\n",
    "    # Remove all the tags that are not meaningful for the extraction.\n",
    "    SCAPE_TAGS = [\"nav\", \"footer\", \"aside\", \"script\", \"style\"]\n",
    "    [tag.decompose() for tag in soup.find_all(SCAPE_TAGS)]\n",
    "\n",
    "    def get_text(tag: Tag) -> Generator[str, None, None]:\n",
    "        for child in tag.children:\n",
    "            if isinstance(child, Doctype):\n",
    "                continue\n",
    "\n",
    "            if isinstance(child, NavigableString):\n",
    "                yield child\n",
    "            elif isinstance(child, Tag):\n",
    "                if child.name in [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]:\n",
    "                    yield f\"{'#' * int(child.name[1:])} {child.get_text()}\\n\\n\"\n",
    "                elif child.name == \"a\":\n",
    "                    yield f\"[{child.get_text(strip=False)}]({child.get('href')})\"\n",
    "                elif child.name == \"img\":\n",
    "                    yield f\"![{child.get('alt', '')}]({child.get('src')})\"\n",
    "                elif child.name in [\"strong\", \"b\"]:\n",
    "                    yield f\"**{child.get_text(strip=False)}**\"\n",
    "                elif child.name in [\"em\", \"i\"]:\n",
    "                    yield f\"_{child.get_text(strip=False)}_\"\n",
    "                elif child.name == \"br\":\n",
    "                    yield \"\\n\"\n",
    "                elif child.name == \"code\":\n",
    "                    parent = child.find_parent()\n",
    "                    if parent is not None and parent.name == \"pre\":\n",
    "                        classes = parent.attrs.get(\"class\", \"\")\n",
    "\n",
    "                        language = next(\n",
    "                            filter(lambda x: re.match(r\"language-\\w+\", x), classes),\n",
    "                            None,\n",
    "                        )\n",
    "                        if language is None:\n",
    "                            language = \"\"\n",
    "                        else:\n",
    "                            language = language.split(\"-\")[1]\n",
    "\n",
    "                        lines: list[str] = []\n",
    "                        for span in child.find_all(\"span\", class_=\"token-line\"):\n",
    "                            line_content = \"\".join(\n",
    "                                token.get_text() for token in span.find_all(\"span\")\n",
    "                            )\n",
    "                            lines.append(line_content)\n",
    "\n",
    "                        code_content = \"\\n\".join(lines)\n",
    "                        yield f\"```{language}\\n{code_content}\\n```\\n\\n\"\n",
    "                    else:\n",
    "                        yield f\"`{child.get_text(strip=False)}`\"\n",
    "\n",
    "                elif child.name == \"p\":\n",
    "                    yield from get_text(child)\n",
    "                    yield \"\\n\\n\"\n",
    "                elif child.name == \"ul\":\n",
    "                    for li in child.find_all(\"li\", recursive=False):\n",
    "                        yield \"- \"\n",
    "                        yield from get_text(li)\n",
    "                        yield \"\\n\\n\"\n",
    "                elif child.name == \"ol\":\n",
    "                    for i, li in enumerate(child.find_all(\"li\", recursive=False)):\n",
    "                        yield f\"{i + 1}. \"\n",
    "                        yield from get_text(li)\n",
    "                        yield \"\\n\\n\"\n",
    "                elif child.name == \"div\" and \"tabs-container\" in child.attrs.get(\n",
    "                    \"class\", [\"\"]\n",
    "                ):\n",
    "                    tabs = child.find_all(\"li\", {\"role\": \"tab\"})\n",
    "                    tab_panels = child.find_all(\"div\", {\"role\": \"tabpanel\"})\n",
    "                    for tab, tab_panel in zip(tabs, tab_panels):\n",
    "                        tab_name = tab.get_text(strip=True)\n",
    "                        yield f\"{tab_name}\\n\"\n",
    "                        yield from get_text(tab_panel)\n",
    "                elif child.name == \"table\":\n",
    "                    thead = child.find(\"thead\")\n",
    "                    header_exists = isinstance(thead, Tag)\n",
    "                    if header_exists:\n",
    "                        headers = thead.find_all(\"th\")\n",
    "                        if headers:\n",
    "                            yield \"| \"\n",
    "                            yield \" | \".join(header.get_text() for header in headers)\n",
    "                            yield \" |\\n\"\n",
    "                            yield \"| \"\n",
    "                            yield \" | \".join(\"----\" for _ in headers)\n",
    "                            yield \" |\\n\"\n",
    "\n",
    "                    tbody = child.find(\"tbody\")\n",
    "                    tbody_exists = isinstance(tbody, Tag)\n",
    "                    if tbody_exists:\n",
    "                        for row in tbody.find_all(\"tr\"):\n",
    "                            yield \"| \"\n",
    "                            yield \" | \".join(\n",
    "                                cell.get_text(strip=True) for cell in row.find_all(\"td\")\n",
    "                            )\n",
    "                            yield \" |\\n\"\n",
    "\n",
    "                    yield \"\\n\\n\"\n",
    "                elif child.name in [\"button\"]:\n",
    "                    continue\n",
    "                else:\n",
    "                    yield from get_text(child)\n",
    "\n",
    "    joined = \"\".join(get_text(soup))\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", joined).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5400ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "d:\\chatbot_project\\RAG-chatbot-custom-auth\\venv\\Lib\\site-packages\\langchain_community\\indexes\\_sql_record_manager.py:61: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# ingestion_service.py\n",
    "import logging\n",
    "import os\n",
    "from typing import Optional, Dict, Any\n",
    "from urllib.parse import urlparse\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import SitemapLoader, RecursiveUrlLoader\n",
    "from langchain_community.indexes._sql_record_manager import SQLRecordManager\n",
    "from langchain_core.indexing import index\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "# from config import WebsiteConfig, IndexingStrategy\n",
    "# from parser import langchain_docs_extractor\n",
    "from embeddings import get_embeddings_model\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class IngestionService:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=4000, \n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        self.embedding = get_embeddings_model()\n",
    "        self.client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def metadata_extractor(meta: dict, soup: BeautifulSoup) -> dict:\n",
    "        \"\"\"Extract metadata from HTML soup\"\"\"\n",
    "        title = soup.find(\"title\")\n",
    "        description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "        html = soup.find(\"html\")\n",
    "        return {\n",
    "            \"source\": meta.get(\"loc\", \"\"),\n",
    "            \"title\": title.get_text() if title else \"\",\n",
    "            \"description\": description.get(\"content\", \"\") if description else \"\",\n",
    "            \"language\": html.get(\"lang\", \"\") if html else \"\",\n",
    "            **meta,\n",
    "        }\n",
    "    \n",
    "    def _extract_domain_from_url(self, url: str) -> str:\n",
    "        \"\"\"Extract domain from URL for collection naming\"\"\"\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc.replace(\"www.\", \"\").replace(\".\", \"_\")\n",
    "        return domain\n",
    "    \n",
    "    def _create_index_name(self, config: WebsiteConfig) -> str:\n",
    "        \"\"\"Create a unique index name based on config\"\"\"\n",
    "        if config.index_name:\n",
    "            return config.index_name\n",
    "        \n",
    "        domain = self._extract_domain_from_url(str(config.url))\n",
    "        return f\"{domain}_{config.strategy}\"\n",
    "    \n",
    "    def load_documents(self, config: WebsiteConfig):\n",
    "        \"\"\"Load documents based on indexing strategy\"\"\"\n",
    "        if config.strategy == IndexingStrategy.SITEMAP:\n",
    "            # Try sitemap first\n",
    "            sitemap_urls = [\n",
    "                f\"{config.url}/sitemap.xml\",\n",
    "                f\"{config.url}/sitemap_index.xml\",\n",
    "                f\"{config.url}/sitemap\",\n",
    "            ]\n",
    "            \n",
    "            for sitemap_url in sitemap_urls:\n",
    "                try:\n",
    "                    loader = SitemapLoader(\n",
    "                        sitemap_url,\n",
    "                        filter_urls=config.filter_urls or [str(config.url)],\n",
    "                        parsing_function=langchain_docs_extractor,\n",
    "                        default_parser=\"lxml\",\n",
    "                        bs_kwargs={\n",
    "                            \"parse_only\": SoupStrainer(\n",
    "                                name=(\"article\", \"title\", \"html\", \"lang\", \"content\")\n",
    "                            ),\n",
    "                        },\n",
    "                        meta_function=self.metadata_extractor,\n",
    "                    )\n",
    "                    return loader.load()\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load sitemap from {sitemap_url}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Fall back to recursive if sitemap not found\n",
    "            config.strategy = IndexingStrategy.RECURSIVE\n",
    "        \n",
    "        if config.strategy == IndexingStrategy.RECURSIVE:\n",
    "            loader = RecursiveUrlLoader(\n",
    "                url=str(config.url),\n",
    "                max_depth=config.max_depth or 2,\n",
    "                extractor=langchain_docs_extractor,\n",
    "                prevent_outside=config.allowed_domains is None,\n",
    "                allowed_domains=config.allowed_domains,\n",
    "                use_async=True,\n",
    "            )\n",
    "            return loader.load()\n",
    "        \n",
    "        raise ValueError(f\"Unsupported strategy: {config.strategy}\")\n",
    "    \n",
    "    def ingest_website(self, config: WebsiteConfig, force_update: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Main ingestion method\"\"\"\n",
    "        try:\n",
    "            # Determine collection name\n",
    "            collection_name = self._create_index_name(config)\n",
    "            \n",
    "            # Initialize vector store\n",
    "            vectorstore = Chroma(\n",
    "                client=self.client,\n",
    "                collection_name=collection_name,\n",
    "                embedding_function=self.embedding,\n",
    "            )\n",
    "            \n",
    "            # Initialize record manager\n",
    "            record_manager = SQLRecordManager(\n",
    "                f\"chroma/{collection_name}\",\n",
    "                db_url=os.getenv(\"RECORD_MANAGER_DB_URL\")\n",
    "            )\n",
    "            record_manager.create_schema()\n",
    "            \n",
    "            # Load documents\n",
    "            logger.info(f\"Loading documents from {config.url} using {config.strategy} strategy\")\n",
    "            docs = self.load_documents(config)\n",
    "            logger.info(f\"Loaded {len(docs)} documents\")\n",
    "            \n",
    "            # Split documents\n",
    "            docs_transformed = self.text_splitter.split_documents(docs)\n",
    "            docs_transformed = [\n",
    "                doc for doc in docs_transformed \n",
    "                if len(doc.page_content) > 10\n",
    "            ]\n",
    "            \n",
    "            # Ensure required metadata\n",
    "            for doc in docs_transformed:\n",
    "                if \"source\" not in doc.metadata:\n",
    "                    doc.metadata[\"source\"] = str(config.url)\n",
    "                if \"title\" not in doc.metadata:\n",
    "                    doc.metadata[\"title\"] = config.name\n",
    "            \n",
    "            # Index documents\n",
    "            indexing_stats = index(\n",
    "                docs_transformed,\n",
    "                record_manager,\n",
    "                vectorstore,\n",
    "                cleanup=\"full\",\n",
    "                source_id_key=\"source\",\n",
    "                force_update=force_update,\n",
    "            )\n",
    "            \n",
    "            # Get collection statistics\n",
    "            collection = self.client.get_collection(collection_name)\n",
    "            num_vectors = collection.count()\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"collection_name\": collection_name,\n",
    "                \"indexing_stats\": indexing_stats,\n",
    "                \"num_documents\": len(docs),\n",
    "                \"num_chunks\": len(docs_transformed),\n",
    "                \"num_vectors\": num_vectors,\n",
    "                \"strategy_used\": config.strategy,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error ingesting website {config.url}: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"collection_name\": getattr(config, 'index_name', 'unknown'),\n",
    "            }\n",
    "\n",
    "# Singleton instance\n",
    "ingestion_service = IngestionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api.py\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List, Dict, Any\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "from config import WebsiteConfig, IndexingStrategy\n",
    "from ingestion_service import ingestion_service\n",
    "\n",
    "app = FastAPI(title=\"Document Ingestion API\")\n",
    "\n",
    "# Store job status\n",
    "ingestion_jobs: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "class IngestionRequest(BaseModel):\n",
    "    url: str\n",
    "    name: Optional[str] = None\n",
    "    index_name: Optional[str] = None\n",
    "    strategy: Optional[str] = \"sitemap\"\n",
    "    filter_urls: Optional[List[str]] = None\n",
    "    allowed_domains: Optional[List[str]] = None\n",
    "    max_depth: Optional[int] = 2\n",
    "    chunk_size: Optional[int] = 4000\n",
    "    chunk_overlap: Optional[int] = 200\n",
    "    force_update: Optional[bool] = False\n",
    "\n",
    "class IngestionResponse(BaseModel):\n",
    "    job_id: str\n",
    "    status: str\n",
    "    message: str\n",
    "    collection_name: Optional[str] = None\n",
    "\n",
    "class JobStatusResponse(BaseModel):\n",
    "    job_id: str\n",
    "    status: str\n",
    "    result: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[str] = None\n",
    "    created_at: datetime\n",
    "    updated_at: datetime\n",
    "\n",
    "def process_ingestion_job(job_id: str, config: WebsiteConfig, force_update: bool):\n",
    "    \"\"\"Background task to process ingestion\"\"\"\n",
    "    try:\n",
    "        ingestion_jobs[job_id][\"status\"] = \"processing\"\n",
    "        ingestion_jobs[job_id][\"updated_at\"] = datetime.now()\n",
    "        \n",
    "        result = ingestion_service.ingest_website(config, force_update)\n",
    "        \n",
    "        ingestion_jobs[job_id].update({\n",
    "            \"status\": \"completed\",\n",
    "            \"result\": result,\n",
    "            \"updated_at\": datetime.now()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        ingestion_jobs[job_id].update({\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": str(e),\n",
    "            \"updated_at\": datetime.now()\n",
    "        })\n",
    "\n",
    "@app.post(\"/ingest\", response_model=IngestionResponse)\n",
    "async def ingest_website(\n",
    "    request: IngestionRequest,\n",
    "    background_tasks: BackgroundTasks\n",
    "):\n",
    "    \"\"\"Start website ingestion\"\"\"\n",
    "    try:\n",
    "        # Generate job ID\n",
    "        job_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Create website name if not provided\n",
    "        name = request.name or f\"Website_{job_id[:8]}\"\n",
    "        \n",
    "        # Create config\n",
    "        config = WebsiteConfig(\n",
    "            url=request.url,\n",
    "            name=name,\n",
    "            index_name=request.index_name,\n",
    "            strategy=IndexingStrategy(request.strategy),\n",
    "            filter_urls=request.filter_urls,\n",
    "            allowed_domains=request.allowed_domains,\n",
    "            max_depth=request.max_depth,\n",
    "            chunk_size=request.chunk_size,\n",
    "            chunk_overlap=request.chunk_overlap,\n",
    "        )\n",
    "        \n",
    "        # Store job\n",
    "        ingestion_jobs[job_id] = {\n",
    "            \"status\": \"pending\",\n",
    "            \"config\": config.dict(),\n",
    "            \"created_at\": datetime.now(),\n",
    "            \"updated_at\": datetime.now(),\n",
    "        }\n",
    "        \n",
    "        # Start background task\n",
    "        background_tasks.add_task(\n",
    "            process_ingestion_job,\n",
    "            job_id,\n",
    "            config,\n",
    "            request.force_update\n",
    "        )\n",
    "        \n",
    "        return IngestionResponse(\n",
    "            job_id=job_id,\n",
    "            status=\"pending\",\n",
    "            message=\"Ingestion job started\",\n",
    "            collection_name=config.index_name\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "@app.get(\"/jobs/{job_id}\", response_model=JobStatusResponse)\n",
    "async def get_job_status(job_id: str):\n",
    "    \"\"\"Check ingestion job status\"\"\"\n",
    "    if job_id not in ingestion_jobs:\n",
    "        raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "    \n",
    "    job = ingestion_jobs[job_id]\n",
    "    return JobStatusResponse(\n",
    "        job_id=job_id,\n",
    "        status=job[\"status\"],\n",
    "        result=job.get(\"result\"),\n",
    "        error=job.get(\"error\"),\n",
    "        created_at=job[\"created_at\"],\n",
    "        updated_at=job[\"updated_at\"]\n",
    "    )\n",
    "\n",
    "@app.get(\"/jobs\")\n",
    "async def list_jobs():\n",
    "    \"\"\"List all ingestion jobs\"\"\"\n",
    "    return {\n",
    "        \"jobs\": [\n",
    "            {\n",
    "                \"job_id\": job_id,\n",
    "                \"status\": job[\"status\"],\n",
    "                \"url\": job[\"config\"][\"url\"],\n",
    "                \"created_at\": job[\"created_at\"],\n",
    "                \"updated_at\": job[\"updated_at\"]\n",
    "            }\n",
    "            for job_id, job in ingestion_jobs.items()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "@app.get(\"/collections\")\n",
    "async def list_collections():\n",
    "    \"\"\"List all collections in ChromaDB\"\"\"\n",
    "    collections = ingestion_service.client.list_collections()\n",
    "    return {\n",
    "        \"collections\": [\n",
    "            {\n",
    "                \"name\": collection.name,\n",
    "                \"metadata\": collection.metadata,\n",
    "                \"count\": collection.count()\n",
    "            }\n",
    "            for collection in collections\n",
    "        ]\n",
    "    }\n",
    "\n",
    "@app.delete(\"/collections/{collection_name}\")\n",
    "async def delete_collection(collection_name: str):\n",
    "    \"\"\"Delete a collection\"\"\"\n",
    "    try:\n",
    "        ingestion_service.client.delete_collection(collection_name)\n",
    "        return {\"success\": True, \"message\": f\"Collection {collection_name} deleted\"}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
